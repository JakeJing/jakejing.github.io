---
title: 'Understanding Jacobian Adjustments for Constrained Parameters in Stan'
date: 2025-07-10
permalink: /posts/2025/07/blog-post-1/
render_with_liquid: false
tags:
  - Jacobian transformation
  - probability density function
  - changes of variables
  - Stan
---



![Probability masses of normal and lognormal distributions within the corresponding intervals](https://raw.githubusercontent.com/JakeJing/jakejing.github.io/master/_posts/pics/jacobian/normal_to_lognormal.png)

The Jacobian adjustment is a key concept in statistical modeling that arises when transforming probability distributions from one space to another. The intuition is that when you change a random variable, you're not just changing the values - you're also changing how "stretched" or "compressed" the probability density becomes at different points. To account for the distortion caused by the transform, the density must be multiplied by a Jacobian adjustment. This ensures that probability masses of corresponding intervals stay unchanged before and after the transform. This is illustrated by the figure above, which compares the probability density functions of a standard normal distribution and its transformed lognormal distribution. Although the shapes of the two distributions differ, the transformation must preserve the probability mass over corresponding intervals.

In Bayesian inference, Jacobian adjustments are especially important when transforming parameters from a constrained space (e.g., the positive real line) to an unconstrained space (e.g., the entire real line), which is commonly done to improve sampling efficiency and numerical stability. In Stan, such transformations are typically handled automatically. When you declare a constrained parameter (e.g., <lower=0>), Stan internally transforms it to an unconstrained space and applies the appropriate Jacobian adjustment to maintain the correct posterior density.

$$\left|f_Y(y) \cdot dy \right| = \left|f_X(x) \cdot dx \right|$$

However, if you manually transform variables inside the transformed parameters block and assign priors to the transformed variables, you need to explicitly include the Jacobian adjustment to preserve the correct log posterior density (lp__). Failing to do so can lead to biased inference. To illustrate how this works, I'll use a simple example of normal distribution, focusing on how Stan handles transformations of the standard deviation parameter $\sigma$ (i.e., <lower=0>) and how we can include a manual Jacobian adjustment.

## 1. Simulate data

I will first simulate some data from a normal distribution with mean 0 and standard deviation 20. A large standard deviation is chosen to make the effect of Jacobian adjustment more pronounced.

```R
data_norm <- list(N = 100, y = rnorm(100, 0, 20))
```


## 2. Posterior parameter estimates

I will include three models to compare posterior parameter estimates and the log posterior density (lp__). 

### Model 1: constrained parameter $\sigma$

The first model is a simple normal distribution with a proper constraint on $\sigma$ (<lower=0>). According to [Stan reference manual](https://mc-stan.org/docs/reference-manual/transforms.html), to avoid having to deal with constraints while simulating the Hamiltonian dynamics during sampling, every (multivariate) parameter in a Stan model is transformed to an unconstrained variable behind the scenes by the model compiler, and Stan handles the Jacobian adjustment automatically.

<script src="https://gist.github.com/JakeJing/946a73e16451cf9725f166b9ca7e5701.js"></script>


![Posterior parameter estimates from model 1](https://raw.githubusercontent.com/JakeJing/jakejing.github.io/master/_posts/pics/jacobian/md1.png)

### Model 2: unconstrained parameter $\sigma$

Now we turn to another model by removing the constraint on $\sigma$. In this case, the parameter $\sigma$ is not a constrained variable, and there is no Jacobian adjustment handled by Stan. This means that the log posterior density (lp__) is biased.


<script src="https://gist.github.com/JakeJing/dd1a3ed6e9953bad1b195164ea5d093b.js"></script>

![Posterior parameter estimates from model 2](https://raw.githubusercontent.com/JakeJing/jakejing.github.io/master/_posts/pics/jacobian/md2.png)



### Model 3: exponential transformation of unconstrained $\sigma$ and Jacobian adjustment

As a comparison, we can also reformulate the model by defining the parameter $\sigma$ as an unconstrained variable, and we then transform it via an exponential function (positive real line). The transformed variable $\sigma\_{exp}$ will be assigned with a prior and used in the model. This is exactly what has happened internally by Stan when you define a parameter with a proper constraint (e.g., <lower=0>). Stan handles the transformation from an unconstrained internal representation to this constrained user-facing value. Thus, we need to include a Jacobian adjustment to preserve the correct log posterior density (lp__).

![Jacobian adjustment of lower bounded scalar in stan](https://raw.githubusercontent.com/JakeJing/jakejing.github.io/master/_posts/pics/jacobian/jacobian.png)


<script src="https://gist.github.com/JakeJing/e87490f37130ce2639b2e1268975259c.js"></script>

![Posterior parameter estimates from model 3](https://raw.githubusercontent.com/JakeJing/jakejing.github.io/master/_posts/pics/jacobian/md3.png)

## 3. Comparison of results

As we can see, the posterior parameter estimates for $\mu$ and $\sigma$ are similar across all three models. However, the log posterior density (lp__) differs between Model 1 and Model 2. This is because Model 1 includes the proper constraint on $\sigma$, while Model 2 does not. The log posterior density in Model 2 is biased due to the missing Jacobian adjustment. Model 3 addresses this issue by including a Jacobian adjustment. In general, if you are interested in parameter inference, it may be not a major concern in this case, but missing Jacobian adjustments can cause serious problems for model comparison (e.g., WAIC, LOO, and Bayes factors).

Note that this example is only for illustration and help you understand the concept of Jacobian adjustment and how Stan handles changes of variables. In practice, you should always use the proper constraint on the parameter and let Stan handle the Jacobian adjustment automatically, which is both more efficient and more reliable.



**Useful links**

- [(Best) A coin toss example with Jacobian transformation](https://rpubs.com/kaz_yos/stan_jacobian)
- [The Jacobian transformation](https://modelassist.epixanalytics.com/space/EA/26575402/The+Jacobian+transformation)
- [Changes of variables](https://mc-stan.org/docs/stan-users-guide/reparameterization.html#changes-of-variables)
- [Transforms](https://mc-stan.org/docs/reference-manual/transforms.html)
- [Laplace method and Jacobian of parameter transformation](https://users.aalto.fi/~ave/casestudies/Jacobian/jacobian.html)



